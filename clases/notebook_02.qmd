---
listing_title: "Clase 02"
title: |
  | \includegraphics[width=5cm]{Imagen5.png}  
  | ECO5008 Modelos predictivos
subtitle: Clase 02 - Modelos de Supervivencia y Weibull aplicados a Salud
format: pdf
editor: visual
author:   
  - Sebasti√°n Ega√±a Santib√°√±ez [{{< fa brands inbox >}}](mailto:segana@fen.uchile.cl)
code-block-bg: true
code-block-border-left: "#FF0000"
---

------------------------------------------------------------------------

# Enlaces del profesor

[{{< fa brands link >}}](https://segana.netlify.app) https://segana.netlify.app

[{{< fa brands github >}}](https://github.com/sebaegana) https://github.com/sebaegana

[{{< fa brands linkedin >}}](https://www.linkedin.com/in/sebastian-egana-santibanez/) https://www.linkedin.com/in/sebastian-egana-santibanez/

------------------------------------------------------------------------

```{r load_packages, message=FALSE, warning=FALSE, include=FALSE}
library(fontawesome)
library(knitr)
library(tidyverse)
```

# Clase 02

# Conceptos iniciales

## Introducci√≥n a supervivencia

Cuando hablamos de supervivencia en t√©rminos de predicciones nos referimos al esfuerzo de modelar el tiempo que transcurre hac√≠a cierto evento. En el caso del √°rea de salud, podemos pensar en el tiempo que transcurre hasta remisi√≥n, alta o rehospitalizaci√≥n. Un √°rea intermedia de aplicaci√≥n, corresponde a la de ingenier√≠a de la confiabilidad, sirviendo para poder determinar tiempo entre fallas o entre reparaciones.

## Elementos claves

-   La variable relevante para ser analizada corresponde al tiempo hasta el evento, considerando $T > 0$

-   Censura: corresponde a evento que por alguna u otra raz√≥n no puede ser observados de manera completa; por ejemplo, si estamos analizando el tiempo antes del alta de los pacientes existir√°n casos de paciente que a√∫n se encuentran hospitalizados pero que dado el momento de selecci√≥n del estudio debemos **censurar** en base al valor que posee al momento del estudio. Este tipo de observaci√≥n solo **a√±ade** a la probabilidad de que el evento ocurra posterior a lo observado y debe ser marcada para incorporarla de manera distinta al an√°lisis.

### Tipos de censura (diagrama)

**Leyenda**

-   `-` tiempo observado
-   `[` inicio
-   `]` fin
-   `|` corte/fin
-   `*` evento observado
-   `?` evento en el intervalo

```         
1) Evento observado (no censurado)
   Sujeto A: [------*------]            ‚Üí observamos T = t

2) Censura a derecha (right censoring)
   Sujeto B: [------------|  ]          ‚Üí sabemos T > C   
   (no ocurri√≥ antes del corte)

3) Censura a izquierda (left censoring)
   Sujeto C:     *-----]                 ‚Üí sabemos T <= L   
   (ocurri√≥ antes del 1er registro)

4) Censura por intervalo (interval censoring)
   Sujeto D: [---?---]                   ‚Üí sabemos L < T <= R 
   (entre dos visitas y relacionada con inspecciones)

5) Censura administrativa (Tipo I, corte com√∫n de calendario)
   Sujeto E: [-------|]                  ‚Üí t√≠picamente ‚Äúa derecha‚Äù

6) Censura Tipo II (por n√∫mero de eventos)
   Cohorte: el estudio termina cuando ocurre el k-√©simo evento
```

## Preguntas

¬øConsidere en los casos de gesti√≥n para los cuales esto podr√≠a ser valioso?

# Distribuci√≥n de Weibull

Se utiliza para modelos los tiempos hasta un evento cuando la tasa de eventos cambia de forma mon√≥tona (crece o decrece).

Par√°metros.

$k$ (forma): indica c√≥mo cambia el riesgo en el tiempo.

-   $k>1$: riesgo creciente (cada vez m√°s probable el evento).
-   $k=1$: riesgo constante (caso exponencial).
-   $k<1$: riesgo decreciente (m√°s probable al inicio).

$\eta$ (escala): fija la escala temporal (en las mismas unidades que t).

Se puede calcular con covariables (otras ariables relevantes), pero para este caso solo utilizaremos la funci√≥n sin otras variables.

## F√≥rmulas clave (Weibull)

Sea $T \sim \text{Weibull}(k,\eta)$ con $k>0$ (forma) y $\eta>0$ (escala), $t>0$.

\begin{itemize}

\item $\textbf{PDF (Weibull)}: \quad f(t)=\frac{k}{\eta} \left(\frac{t}{\eta}\right)^{k-1} \exp\!\big[-(t/\eta)^k\big]$

\item $\textbf{CDF:}\quad F(t)=1-\exp\ \big[-(t/\eta)^k\big] $

\item $ \textbf{Supervivencia:}\quad S(t)=\exp\!\big[-(t/\eta)^k\big] $

\item $ \textbf{Riesgo (hazard):}\quad h(t)=\dfrac{k}{\eta}\ \left(\frac{t}{\eta}\right)^{k-1} $

\item $ \textbf{Riesgo acumulado:}\quad H(t)=-\ln S(t)=(t/\eta)^k$

\item $ \textbf{Percentil }p:\quad t_p=\eta\,\big[-\ln(1-p)\big]^{1/k}$

\item $ \textbf{Mediana:}\quad t_{0.5}=\eta\,(\ln 2)^{1/k}$

\item $ \textbf{Media:}\quad \mathbb{E}[T]=\eta\,\Gamma\!\Big(1+\tfrac{1}{k}\Big) $

\end{itemize}

En la pr√°ctica, el software (R en este caso) te devuelve $k$, $\eta$, la media, la mediana y los intervalos sin que tengas que calcularlos a mano.

## Ejemplo simplificado

Tenamos los siguientes datos de altas pacientes con neumon√≠a y queremos predecir el tiempo promedio de hospitalizaci√≥n en d√≠as:

```{r message=FALSE, warning=FALSE}
#| eval: false
#| include: true
#| echo: true

tiempo <- c(2,3,1,5,7,8,9,3,4,6,2,10,11,7,5,4,12,8,9,6)
alta   <- c(1,1,1,1,1,0,0,1,1,1,1,0,0,1,1,1,0,1,1,1)

```

Recordar que ac√° la censura corresponde a los pacientes que no han sido dados de alta (alta = 0).

```{r message=FALSE, warning=FALSE}
#| eval: true
#| include: true
#| echo: false

tiempo <- c(2,3,1,5,7,8,9,3,4,6,2,10,11,7,5,4,12,8,9,6)
alta   <- c(1,1,1,1,1,0,0,1,1,1,1,0,0,1,1,1,0,1,1,1)

df <- tibble(TCC = tiempo, DELTA = alta)

units_label <- "d√≠as"

# --- Conteos clave ---
n_total    <- nrow(df)
n_event    <- sum(df$DELTA == 1)
n_censored <- sum(df$DELTA == 0)
event_rate <- n_event / n_total

kable(
  data.frame(
    Total = n_total,
    Eventos_DELTA1 = n_event,
    Censuras_DELTA0 = n_censored,
    Proporcion_evento = round(event_rate, 3)
  ),
  caption = "Conteos: total, eventos (DELTA=1), censuras (DELTA=0)"
)

# --- Resumen estad√≠stico (global y por estado) ---
quant_levels <- c(0, .1, .25, .5, .75, .9, 1)
qnames <- paste0("q", quant_levels*100)

resumen_global <- df %>%
  summarise(
    n     = n(),
    min   = min(TCC),
    mean  = mean(TCC),
    sd    = sd(TCC),
    median= median(TCC),
    max   = max(TCC),
  )


resumen_por_estado <- df %>%
  group_by(DELTA) %>%
  summarise(
    n     = n(),
    min   = min(TCC),
    mean  = mean(TCC),
    sd    = sd(TCC),
    median= median(TCC),
    max   = max(TCC),
    .groups = "drop"
  )

kable(resumen_global, digits = 3,
      caption = paste("Resumen global de TCC (", units_label, ")", sep=""))

kable(resumen_por_estado, digits = 3,
      caption = paste("Resumen de TCC por estado DELTA (", units_label, ")", sep=""))
```

Veamos el an√°lisis de Weibull para estos datos:

```{r message=FALSE, warning=FALSE}
#| eval: true
#| include: true
#| echo: false

library(survival)
library(fitdistrplus)

# -----------------------------
# Ajuste SIN censura (solo eventos)
# -----------------------------
x_evt <- df$TCC[df$DELTA == 1]
fd_nc <- fitdistrplus::fitdist(x_evt, "weibull")
k_nc   <- unname(fd_nc$estimate["shape"])
lam_nc <- unname(fd_nc$estimate["scale"])

# -----------------------------
# Ajuste CON censura (todos)
# -----------------------------
ajuste <- survreg(Surv(TCC, DELTA) ~ 1, dist = "weibull", data = df)
mu_hat <- as.numeric(coef(ajuste))   # intercepto
sig    <- ajuste$scale               # œÉ
k_c    <- 1 / sig                    # shape
lam_c  <- exp(mu_hat)                # scale

# -----------------------------
# Funciones y res√∫menes
# -----------------------------
w_tp   <- function(p,k,lam) lam * (-log(1-p))^(1/k)
w_med  <- function(k,lam)   lam * (log(2))^(1/k)
w_mean <- function(k,lam)   lam * gamma(1 + 1/k)

summ_block <- function(k, lam, caso) {
  tibble(
    Caso    = caso,
    Mediana = w_med(k, lam),
    Media   = w_mean(k, lam),
    `p=0.1` = w_tp(0.1, k, lam),
    `p=0.5` = w_tp(0.5, k, lam),
    `p=0.9` = w_tp(0.9, k, lam)
  )
}

summ_tbl <- bind_rows(
  summ_block(k_nc, lam_nc, "Sin censura"),
  summ_block(k_c,  lam_c,  "Con censura")
) |> mutate(across(where(is.numeric), ~ round(., 4)))

params_tbl <- tibble(
  Caso = c("Sin censura", "Con censura"),
  `shape (k)` = c(round(k_nc, 4), round(k_c, 4)),
  `scale (Œª)` = c(round(lam_nc, 4), round(lam_c, 4))
)

# -----------------------------
# Tablas (solo kable)
# -----------------------------
kable(params_tbl,
      booktabs = TRUE,
      caption = "Par√°metros Weibull 2P por caso")

kable(summ_tbl,
      booktabs = TRUE,
      caption = "Mediana, media y percentiles t_p (p=0.1, 0.5, 0.9)")
```

# Actividad aplicada

Recuerden, seguimos siendo un equipo de analistas. Tenemos datos relacionados con tiempo de cirug√≠as card√≠acas en donde nuestro inter√©s se relaciona con estimar el tiempo de la operaci√≥n hasta que un paciente muere.

## Estimaci√≥n de Weibull

### EDA

Veamos algunas estad√≠sticas descriptivas:

```{r message=FALSE, warning=FALSE}
#| eval: true
#| include: true
#| echo: false

library(readxl)
library(dplyr)
library(knitr)

# --- Par√°metros ---
raw_url    <- "https://raw.githubusercontent.com/Raydonal/ML-Weibull/main/viarapida.xlsm"
local_dir  <- "data"
local_path <- file.path(local_dir, "viarapida.xlsm")
sheet_name <- "viarapida"

# --- Utilidad: descarga con reintentos y backoff exponencial ---
download_with_retry <- function(url, destfile, mode = "wb", quiet = TRUE,
                                retries = 5, initial_wait = 2) {
  wait <- initial_wait
  for (i in seq_len(retries)) {
    ok <- tryCatch({
      download.file(url, destfile, mode = mode, quiet = quiet)
      TRUE
    }, error = function(e) FALSE, warning = function(w) FALSE)
    if (ok && file.exists(destfile) && file.info(destfile)$size > 0) {
      message(sprintf("‚úÖ Descarga OK en intento %d.", i))
      return(TRUE)
    } else {
      if (i < retries) {
        message(sprintf("‚è≥ Falla intento %d. Reintentando en %ds...", i, wait))
        Sys.sleep(wait)
        wait <- min(wait * 2, 60)  # tope 60s
      }
    }
  }
  return(FALSE)
}

# --- 1) Intentar descargar a un archivo temporal ---
tmp <- tempfile(fileext = ".xlsm")
download_ok <- download_with_retry(raw_url, tmp)

# --- 2) Seleccionar fuente: tmp si descarga OK; si no, local; si no, error claro ---
file_to_read <- NULL
if (download_ok) {
  file_to_read <- tmp
  # cachear una copia local para modo offline
  if (!dir.exists(local_dir)) dir.create(local_dir, recursive = TRUE, showWarnings = FALSE)
  file.copy(tmp, local_path, overwrite = TRUE)
  message(sprintf("üíæ Copia cacheada en: %s", normalizePath(local_path)))
} else if (file.exists(local_path)) {
  file_to_read <- local_path
  message(sprintf("üìÇ Usando copia local: %s", normalizePath(local_path)))
} else {
  stop("‚ùå No se pudo descargar el .xlsm y no existe copia local en 'data/'.")
}

# --- 3) Verificar que la hoja exista (xlsm puede tener varias hojas) ---
sheets <- readxl::excel_sheets(path = file_to_read)
if (!(sheet_name %in% sheets)) {
  stop(sprintf("‚ùå La hoja '%s' no existe. Hojas disponibles: %s",
               sheet_name, paste(sheets, collapse = ", ")))
}

# --- 4) Leer datos desde la hoja 'viarapida' y limpiar ---
df <- readxl::read_excel(file_to_read, sheet = sheet_name, .name_repair = "unique") %>%
  transmute(
    TCC   = suppressWarnings(as.numeric(TCC)),
    DELTA = suppressWarnings(as.integer(DELTA))
  ) %>%
  filter(is.finite(TCC), TCC > 0, DELTA %in% c(0L, 1L))

stopifnot(nrow(df) > 0)

# --- 5) Resumenes y conteos ---
units_label <- "horas"

n_total    <- nrow(df)
n_event    <- sum(df$DELTA == 1L)
n_censored <- sum(df$DELTA == 0L)
event_rate <- n_event / n_total

kable(
  data.frame(
    Total             = n_total,
    Eventos_DELTA1    = n_event,
    Censuras_DELTA0   = n_censored,
    Proporcion_evento = round(event_rate, 3)
  ),
  caption = "Conteos: total, eventos (DELTA=1), censuras (DELTA=0)"
)

resumen_global <- df %>%
  summarise(
    n      = n(),
    min    = min(TCC),
    mean   = mean(TCC),
    sd     = sd(TCC),
    median = median(TCC),
    max    = max(TCC)
  )

resumen_por_estado <- df %>%
  group_by(DELTA) %>%
  summarise(
    n      = n(),
    min    = min(TCC),
    mean   = mean(TCC),
    sd     = sd(TCC),
    median = median(TCC),
    max    = max(TCC),
    .groups = "drop"
  )

kable(resumen_global, digits = 3,
      caption = sprintf("Resumen global de TCC (%s)", units_label))

kable(resumen_por_estado, digits = 3,
      caption = sprintf("Resumen de TCC por estado DELTA (%s)", units_label))

```

Consideremos realizar un histograma para ver la distribuci√≥n de las horas de operaci√≥n:

```{r message=FALSE, warning=FALSE}
#| eval: true
#| include: true
#| echo: false

# --- Histogramas + densidad ---
ggplot(df, aes(TCC)) +
  geom_histogram(bins = 30, aes(y = after_stat(density))) +
  geom_density(linewidth = 1) +
  labs(title = "Histograma + Densidad de TCC (global)",
       x = paste("TCC (", units_label, ")", sep=""),
       y = "Densidad") +
  theme_minimal()

ggplot(df, aes(TCC, fill = factor(DELTA))) +
  geom_histogram(bins = 30, position = "identity", alpha = .4) +
  labs(title = "Histograma por estado (DELTA: 1=muerte, 0=censura)",
       x = paste("TCC (", units_label, ")", sep=""),
       fill = "DELTA") +
  theme_minimal()

```

Otros gr√°ficos relevantes:

```{r message=FALSE, warning=FALSE}
#| eval: true
#| include: true
#| echo: false

# --- Boxplot por estado ---
ggplot(df, aes(x = factor(DELTA), y = TCC)) +
  geom_boxplot(outlier.alpha = .5) +
  labs(title = "Boxplot de TCC por estado",
       x = "DELTA (1=muerte, 0=censura)",
       y = paste("TCC (", units_label, ")", sep="")) +
  theme_minimal()

# --- ECDF (distribuci√≥n emp√≠rica acumulada) ---
ggplot(df, aes(TCC)) +
  stat_ecdf(geom = "step") +
  labs(title = "ECDF de TCC (global)",
       x = paste("TCC (", units_label, ")", sep=""),
       y = "F_hat(t)") +
  theme_minimal()
```

### Weibull 2P: c√°lculo con y sin censura

```{r message=FALSE, warning=FALSE}
#| eval: true
#| echo: false
#| include: true

# 2) Ajustes Weibull
#   a) SIN censura: solo eventos
x_evt <- df$TCC[df$DELTA == 1]
fd_nc <- fitdistrplus::fitdist(x_evt, "weibull")
k_nc   <- unname(fd_nc$estimate["shape"])
lam_nc <- unname(fd_nc$estimate["scale"])

#   b) CON censura: todos
fit_c  <- flexsurv::flexsurvreg(Surv(TCC, DELTA) ~ 1, data = df, dist = "weibull")
k_c    <- fit_c$res["shape","est"]
lam_c  <- fit_c$res["scale","est"]

params_tbl <- tibble(
  Caso = c("Sin censura (DELTA==1)", "Con censura (Surv)"),
  `shape (k)` = c(k_nc, k_c),
  `scale (Œ∑)` = c(lam_nc, lam_c)
)
kable(params_tbl, digits = 4, caption = "Par√°metros Weibull 2P por caso")

# 3) Funciones y res√∫menes
w_pdf <- function(t,k,lam) (k/lam)*(t/lam)^(k-1)*exp(-(t/lam)^k)
w_cdf <- function(t,k,lam) 1 - exp(-(t/lam)^k)
w_sur <- function(t,k,lam) exp(-(t/lam)^k)
w_haz <- function(t,k,lam) (k/lam)*(t/lam)^(k-1)
w_H   <- function(t,k,lam) (t/lam)^k
w_tp  <- function(p,k,lam) lam * (-log(1-p))^(1/k)
w_med <- function(k,lam)   lam * (log(2))^(1/k)
w_mean<- function(k,lam)   lam * gamma(1 + 1/k)

# puntos de evaluaci√≥n (quintiles del rango observado)
t_eval <- quantile(df$TCC, probs = c(.1,.3,.5,.7,.9), na.rm = TRUE) |> as.numeric()
t_cols <- paste0("t=", round(t_eval, 2))

calc_block <- function(k, lam, caso, t_eval, t_cols) {
  vals <- list(
    `PDF f(t)`            = w_pdf(t_eval, k, lam),
    `CDF F(t)`            = w_cdf(t_eval, k, lam),
    `Supervivencia S(t)`  = w_sur(t_eval, k, lam),
    `Riesgo h(t)`         = w_haz(t_eval, k, lam),
    `Riesgo acum. H(t)`   = w_H  (t_eval, k, lam)
  )
  mat <- do.call(rbind, lapply(vals, function(v) round(v, 6)))
  colnames(mat) <- t_cols
  tibble(Caso = caso, Funcion = names(vals)) |>
    bind_cols(as_tibble(mat))
}

tbl_fun_nc <- calc_block(k_nc, lam_nc, "Sin censura", t_eval, t_cols)
tbl_fun_c  <- calc_block(k_c,  lam_c,  "Con censura", t_eval, t_cols)

kable(bind_rows(tbl_fun_nc, tbl_fun_c),
      caption = "Funciones evaluadas en t = p10, p30, p50, p70, p90 del TCC")

# Res√∫menes: mediana, media y percentiles p
p_vec <- c(0.1, 0.5, 0.9)
summ_block <- function(k, lam, caso) {
  tibble(
    Caso = caso,
    Mediana = w_med(k, lam),
    Media   = w_mean(k, lam)
  ) |>
    bind_cols(
      tibble(Percentil = paste0("p=", p_vec),
             t_p = w_tp(p_vec, k, lam)) |>
        pivot_wider(names_from = Percentil, values_from = t_p)
    )
}
summ_tbl <- bind_rows(
  summ_block(k_nc, lam_nc, "Sin censura"),
  summ_block(k_c,  lam_c,  "Con censura")
)
kable(summ_tbl |> mutate(across(where(is.numeric), ~ round(., 4))),
      caption = "Mediana, media y percentiles t_p (p=0.1, 0.5, 0.9)")

```

Para la interpretaci√≥n de las tablas: Intuici√≥n r√°pida

-   $S(t)$: probabilidad de seguir sin evento en el tiempo t.
-   $F(t)$: probabilidad de haber tenido el evento antes del tiempo t.
-   $h(t)$: tasa instant√°nea a la que cae $S(t)$; si $h(t)$ sube, $S(t)$ cae m√°s r√°pido.
-   $H(t)$: riesgo acumulado

## Preguntas

-   ¬øCu√°les ser√≠an las aplicaciones de gesti√≥n de este an√°lisis?

# Una aplicaci√≥n distinta

Se sabe que las maquinas de hemodi√°lisis son necesarias para poder mantener el tratamiento de los pacientes, requiriendo siempre un funcionamiento eficiente y continuo. Utilizando la distribuci√≥n de Weibull podemos caracterizar la din√°mica de fallas para dichas m√°quinas.

Tenemos los eventos de fallas para tres m√°quinas de hemodi√°lisis distintas:

```{r message=FALSE, warning=FALSE}
#| eval: true
#| echo: false
#| include: true

# Librer√≠as
library(tibble)
library(dplyr)
library(tidyr)
library(lubridate)

# 1Ô∏è‚É£ Dataframe ancho (igual a tu tabla)
failures <- tribble(
  ~Failure_no, ~M1_date,       ~M1_TBF, ~M2_date,       ~M2_TBF, ~M3_date,       ~M3_TBF,
  1, "29/01/2014", 1085,  "05/06/2015", 2450,  "29/05/2013", 413,
  2, "04/01/2016", 1904,  "29/05/2017", 2040.5, "12/07/2013", 101.5,
  3, "19/10/2016", 609,   "07/08/2017", 192.5,  "01/09/2014", 1130.5,
  4, "24/10/2016", 10.5,  "28/02/2018", 549.5,  "05/06/2015", 763,
  5, "29/05/2017", 605.5, "03/08/2018", 311.5,  "09/11/2015", 427,
  6, "06/03/2020", 2792,  "06/03/2020", 584.5,  "07/08/2017", 1750,
  7, "12/11/2020", 392,   "03/08/2020", 280,    "31/10/2018", 1228.5,
  8, NA,           NA,     NA,           NA,     "09/08/2019", 780.5,
  9, NA,           NA,     NA,           NA,     "06/03/2020", 560,
 10, NA,           NA,     NA,           NA,     "29/07/2020", 255.5,
 11, NA,           NA,     NA,           NA,     "07/01/2022", 1456
)

# --- pivot + parseo de fechas + selecci√≥n (forzando dplyr/ tidyr) ---
failures_long <- failures |>
  tidyr::pivot_longer(
    cols = dplyr::starts_with("M"),
    names_to = c("machine", ".value"),
    names_pattern = "(M[0-9])_(date|TBF)"
  ) |>
  dplyr::mutate(
    Date_of_failure = lubridate::dmy(.data$date),
    TBF = as.numeric(.data$TBF)
  ) |>
  dplyr::select(machine, Failure_no, Date_of_failure, TBF) |>
  dplyr::arrange(machine, Failure_no)

knitr::kable(failures_long, format = "markdown",
             caption = "Fallas de m√°quinas")


```

Estimamos los par√°metros de Weibull para cada maqu√≠na:

```{r message=FALSE, warning=FALSE}
#| eval: true
#| echo: false
#| include: true
# Paquetes
library(fitdistrplus)

# Funciones Weibull
w_tp   <- function(p,k,lam) lam * (-log(1-p))^(1/k)
w_med  <- function(k,lam)   lam * (log(2))^(1/k)
w_mean <- function(k,lam)   lam * gamma(1 + 1/k)

# Ajuste por m√°quina
ajustes <- failures_long |>
  dplyr::filter(!is.na(.data$TBF)) |>
  dplyr::group_by(.data$machine) |>
  dplyr::summarise(fit = list(fitdistrplus::fitdist(.data$TBF, "weibull")),
                   .groups = "drop")

# Extraer par√°metros y m√©tricas
resumen <- ajustes |>
  dplyr::rowwise() |>
  dplyr::mutate(
    k   = unname(fit$estimate["shape"]),
    lam = unname(fit$estimate["scale"]),
    Mediana = w_med(k, lam),
    Media   = w_mean(k, lam),
    `p=0.1` = w_tp(0.1, k, lam),
    `p=0.5` = w_tp(0.5, k, lam),
    `p=0.9` = w_tp(0.9, k, lam)
  ) |>
  dplyr::ungroup() |>
  dplyr::transmute(                               # usamos transmute para evitar select()
    machine,
    `shape (k)` = k,
    `scale (Œ∑)` = lam,
    Mediana, Media, `p=0.1`, `p=0.5`, `p=0.9`
  ) |>
  dplyr::mutate(dplyr::across(where(is.numeric), ~ round(.x, 4)))

knitr::kable(resumen, format = "markdown",
             caption = "Weibull 2P por componente (sin censura): par√°metros y res√∫menes")

```

## Preguntas

-   ¬øQu√© conclusiones podemos sacar de los n√∫meros obtenidos?
-   ¬øQu√© aplicaciones de negocio/gesti√≥n puede considerar?

## Intervalo √≥ptimo de mantenci√≥n

Considerando que ya podemos caracterizar la din√°mica de fallas para cada m√°quina, ¬øpodr√≠amos hacer alg√∫n an√°lisis para poder tener alguna estrageia que permita evitar la falla de la maquinaria? Ac√° debemos entender la diferencia entre falla correcta y falla preventiva:

-   Falla correctiva: generar costos de reparaci√≥n, pero a la vez costos relacionados con la interrupci√≥n operativa debido a la falla.

-   Falla preventiva: debido a que puede ser planificada, se asume que genera solo los costos de la mantenci√≥n preventiva (por ejemplo un overhaul)

No se tienen en cuenta costos de inspecci√≥n, para simplificar el an√°lisis.

### Estrategia de mantenci√≥n

La din√°mica de mantenci√≥n, cuando existe mantenimiento preventivo, considera la existencia de mantenimiento preventivo y mantenimiento correctivo que conviven de manera conjunta. Se debe entender que incluso con intervalos muy cortos de mantenciones preventivas nos enfrentamos igual a la posibilidad de eventos de mantenci√≥n correctivos. Es debido a esto que la estrategia de mantenci√≥n en dicho caso es una combinaci√≥n de preventivo con correctivo que minimiza el costo de dicha estrategia de mantenci√≥n.

El punto para optimizar la estrategia de mantenci√≥n corresponde al punto donde se minimiza la siguiente funci√≥n:

$$C(T) = \frac{C_{PM}}{T} \;+\; \frac{C_{CM}}{T}\,\lambda(T)$$ Donde

-   $C_{PM}$: costo del mantenimiento preventivo
-   $C_{CM}$: costo del mantenimiento correctivo
-   $T$: intervalo de mantenimiento preventivo
-   $\lambda(T)$: tasa de falla (hazard rate) al tiempo

Siendo $\lambda(T)$:

$$
C(T) = 
\frac{k}{\eta}
\left(
\frac{T}{\eta}
\right)^{k-1}
$$

Para m√°s informaci√≥n: [Pardus Consulting](https://pardusconsulting.com/articles/how-to-calculate-the-optimal-maintenance-interval)

```{r message=FALSE, warning=FALSE}
#| eval: true
#| echo: false
#| include: true
# Solo dependencias imprescindibles
library(fitdistrplus)
library(knitr)

# ---- Costos (solo importa el ratio) ----
C_PM <- 1
C_CM <- 20 * C_PM

# ---- Funciones Weibull y costo por hora (renovaci√≥n exacta) ----
S <- function(t, k, eta) exp(-(t/eta)^k)

E_cycle_len <- function(T, k, eta) {
  # ‚à´_0^T S(t) dt (num√©rico)
  integrate(function(x) S(x, k, eta), lower = 0, upper = T,
            subdivisions = 2000, rel.tol = 1e-8)$value
}

cost_per_hour_renewal <- function(T, k, eta, C_PM, C_CM) {
  num <- C_PM * S(T, k, eta) + C_CM * (1 - S(T, k, eta))
  den <- E_cycle_len(T, k, eta)
  num / den
}

get_opt_T <- function(k, eta, C_PM, C_CM) {
  # Malla de b√∫squeda alrededor de la escala (ajusta si quieres)
  grid_T <- seq(0.2 * eta, 2.0 * eta, length.out = 200)
  costs  <- sapply(grid_T, cost_per_hour_renewal,
                   k = k, eta = eta, C_PM = C_PM, C_CM = C_CM)
  i_min <- which.min(costs)
  c(T_opt = grid_T[i_min], Costo_h_min = costs[i_min])
}

# ---- Estimar por m√°quina (base R) ----
machines <- unique(failures_long$machine)
rows <- lapply(machines, function(m) {
  x <- failures_long$TBF[failures_long$machine == m & !is.na(failures_long$TBF)]
  fit <- fitdistrplus::fitdist(x, "weibull")
  k   <- unname(fit$estimate["shape"])
  eta <- unname(fit$estimate["scale"])
  opt <- get_opt_T(k, eta, C_PM, C_CM)
  data.frame(
    machine = m,
    k = k,
    eta = eta,
    T_opt = opt["T_opt"],
    Costo_h_min = opt["Costo_h_min"],
    check.names = FALSE
  )
})

res <- do.call(rbind, rows)
is_num <- sapply(res, is.numeric)
res[ , is_num] <- lapply(res[ , is_num, drop = FALSE], function(z) round(z, 4))

knitr::kable(res, format = "markdown",
             caption = "Intervalo √≥ptimo de mantenimiento preventivo (T*) por m√°quina con C_CM = 10√óC_PM")


```

# Referencias

-   Cavalcante, T., Ospina, R., Leiva, V., Cabezas, X., & Martin-Barreiro, C. (2023). Weibull regression and machine learning survival models: Methodology, comparison, and application to biomedical data related to cardiac surgery. Biology, 12(3), 442.

-   Fenina, S., Jendoubi, S., & Bouchoucha, F. (2023). Failure rate estimation by Weibull distribution in a stochastic environment: application to the hemodialysis machine. Reliability: Theory & Applications, 18(3 (74)), 450-463.

-   Nketiah, E. A. (2021). Parameter Estimation of the Weibull Distribution; Comparison of the Least-Squares Method and the Maximum Likelihood Estimation. Int. J. Adv. Eng. Res. Sci, 8, 210-224.
